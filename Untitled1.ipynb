{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required packages\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the installed location of Tesseract-OCR in your system\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from which text needs to be extracted\n",
    "\n",
    "img = cv2.imread('ocr-a-font-sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to RGB scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox\n",
      "jumped over the 5\n",
      "lazy dogs!\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pytesseract.image_to_string(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', '32', '293', '87', '362', '0']\n",
      "['h', '96', '293', '135', '362', '0']\n",
      "['e', '145', '292', '191', '344', '0']\n",
      "['q', '225', '274', '268', '344', '0']\n",
      "['u', '282', '292', '321', '343', '0']\n",
      "['i', '335', '293', '344', '362', '0']\n",
      "['c', '353', '292', '396', '344', '0']\n",
      "['k', '403', '293', '444', '362', '0']\n",
      "['b', '478', '292', '521', '362', '0']\n",
      "['r', '532', '293', '558', '344', '0']\n",
      "['o', '561', '292', '606', '344', '0']\n",
      "['w', '610', '293', '677', '343', '0']\n",
      "['n', '684', '293', '723', '344', '0']\n",
      "['f', '759', '293', '788', '363', '0']\n",
      "['o', '789', '292', '834', '344', '0']\n",
      "['x', '839', '293', '884', '343', '0']\n",
      "['j', '26', '166', '45', '255', '0']\n",
      "['u', '59', '185', '98', '236', '0']\n",
      "['m', '111', '186', '180', '237', '0']\n",
      "['p', '193', '167', '236', '237', '0']\n",
      "['e', '224', '166', '265', '255', '0']\n",
      "['d', '243', '185', '339', '255', '0']\n",
      "['o', '377', '185', '422', '237', '0']\n",
      "['v', '427', '186', '472', '236', '0']\n",
      "['e', '450', '185', '491', '237', '0']\n",
      "['r', '476', '185', '559', '237', '0']\n",
      "['t', '587', '185', '611', '253', '0']\n",
      "['h', '619', '186', '658', '255', '0']\n",
      "['e', '668', '185', '714', '237', '0']\n",
      "['5', '749', '185', '794', '254', '0']\n",
      "['l', '37', '79', '46', '148', '0']\n",
      "['a', '55', '78', '100', '130', '0']\n",
      "['z', '106', '79', '149', '129', '0']\n",
      "['y', '152', '59', '197', '129', '0']\n",
      "['d', '228', '78', '271', '148', '0']\n",
      "['o', '282', '78', '327', '130', '0']\n",
      "['g', '334', '59', '377', '130', '0']\n",
      "['s', '359', '59', '401', '148', '0']\n",
      "['!', '387', '78', '452', '148', '0']\n"
     ]
    }
   ],
   "source": [
    "#detecting all characters\n",
    "\n",
    "hImg,wImg,_ = img.shape\n",
    "boxes = pytesseract.image_to_boxes(img)\n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    print(b)\n",
    "    x,y,w,h = int(b[1]),int(b[2]),int(b[3]),int(b[4])\n",
    "    cv2.rectangle(img, (x,hImg-y), (w, hImg-h), (0,0,255),1)\n",
    "    cv2.putText(img, b[0], (x,hImg-y-35), cv2.FONT_HERSHEY_COMPLEX,1,(50,50,225),2)\n",
    "\n",
    "\n",
    "#to display image\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from which text needs to be extracted\n",
    "\n",
    "img = cv2.imread('ocr-a-font-sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to RGB scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detecting numbers only\n",
    "\n",
    "hImg,wImg,_ = img.shape\n",
    "cong = r'--oem 3 --psm 6 outputbase digits'\n",
    "boxes = pytesseract.image_to_boxes(img, config=cong)\n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    print(b)\n",
    "    x,y,w,h = int(b[1]),int(b[2]),int(b[3]),int(b[4])\n",
    "    cv2.rectangle(img, (x,hImg-y), (w, hImg-h), (0,0,255),1)\n",
    "    cv2.putText(img, b[0], (x,hImg-y-35), cv2.FONT_HERSHEY_COMPLEX,1,(50,50,225),2)\n",
    "\n",
    "\n",
    "#to display image\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from which text needs to be extracted\n",
    "\n",
    "img = cv2.imread('download.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to RGB scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detecting words\n",
    "\n",
    "hImg,wImg,_ = img.shape\n",
    "boxes = pytesseract.image_to_data(img)\n",
    "count = 0;\n",
    "for b in boxes.splitlines():\n",
    "    if count !=0:\n",
    "        b = b.split()\n",
    "        print(b)\n",
    "        if len(b)==12:\n",
    "            x,y,w,h = int(b[6]), int(b[7]), int(b[8]), int(b[9])\n",
    "            cv2.rectangle(img, (x,y), (w+x,h+y), (0,0,255),1)\n",
    "            cv2.putText(img, b[11], (x,y), cv2.FONT_HERSHEY_COMPLEX, 1, (50,50,255),2)\n",
    "    count = count + 1\n",
    "\n",
    "#to display image\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from which text needs to be extracted\n",
    "\n",
    "img = cv2.imread('download.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to RGB scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to recognize text and save the content in text file\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Performing OTSU threshold\n",
    "ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Specify structure shape and kernel size.\n",
    "# Kernel size increases or decreases the area\n",
    "# of the rectangle to be detected.\n",
    "# A smaller value like (10, 10) will detect\n",
    "# each word instead of a sentence.\n",
    "rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18))\n",
    "\n",
    "# Appplying dilation on the threshold image\n",
    "dilation = cv2.dilate(thresh1, rect_kernel, iterations=1)\n",
    "\n",
    "# Finding contours\n",
    "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL,\n",
    "                                       cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Creating a copy of image\n",
    "im2 = img.copy()\n",
    "\n",
    "# A text file is created and flushed\n",
    "file = open(\"recognized.txt\", \"w+\")\n",
    "file.write(\"\")\n",
    "file.close()\n",
    "\n",
    "# Looping through the identified contours\n",
    "# Then rectangular part is cropped and passed on\n",
    "# to pytesseract for extracting text from it\n",
    "# Extracted text is then written into the text file\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # Drawing a rectangle on copied image\n",
    "    rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Cropping the text block for giving input to OCR\n",
    "    cropped = im2[y:y + h, x:x + w]\n",
    "\n",
    "    # Open the file in append mode\n",
    "    file = open(\"recognized.txt\", \"a\")\n",
    "\n",
    "    # Apply OCR on the cropped image\n",
    "    text = pytesseract.image_to_string(cropped)\n",
    "\n",
    "    # Appending the text into file\n",
    "    file.write(text)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    # Close the file\n",
    "    file.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
